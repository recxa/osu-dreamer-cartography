# VAE Latent Model Training Config - Cross-Validation Split
# Auto-generated by create_cv_split.py
#
# Split: song groups with 3+ mappers held out for test.
# Train: 579 beatmapsets (288 groups)
# Test:  271 beatmapsets (80 groups) [held out]
#
# Changes from latent_model.yml:
#   - data.data_path -> osu-dreamer-preprocessed-train/
#   - trainer.logger.name -> latent_cv

seed_everything: true
trainer:
  accelerator: mps
  max_epochs: -1
  devices: 1
  precision: 32-true
  enable_checkpointing: true
  callbacks:
  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      monitor: val/l2_rec
      mode: min
      save_top_k: 1
  - class_path: pytorch_lightning.callbacks.LearningRateMonitor
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: /Users/red/Downloads/rcx26/OSUxMIR/experiments/latent-cartography/runs
      name: latent_cv
  enable_progress_bar: true
  log_every_n_steps: 1
  enable_model_summary: true
  val_check_interval: 1000
  check_val_every_n_epoch: null
data:
  data_path: /Users/red/Downloads/rcx26/OSUxMIR/experiments/latent-cartography/data/osu-dreamer-preprocessed-train
  seq_len: 1024
  batch_size: 8
  num_workers: 4
  val_size: 64
model:
  opt_args:
    lr: 0.002
    weight_decay: 0.0
  lr_schedule_args:
    warmup_steps: 500
    warmup_init: 0.01
  grad_accum_steps: 2
  critic_steps_per_gen: 1
  gp_factor: 10.0
  gan_factor: 5e-3
  fm_factor: 1.0
  pixel_factor: 0.0
  kl_factor: 0.0001
  emb_dim: 32
  h_dim: 360
  audio_h_dim: 32
  ae_args:
    strides:
    - 2
    - 3
    - 3
    layer_args:
      num_stacks: 1
      stack_depth: 4
  critic_args:
    spec_features: 32
    scales: 3
    convs:
    - - 16
      - 3
      - 1
      - 1
    - - 64
      - 5
      - 3
      - 4
    - - 256
      - 5
      - 3
      - 16
    - - 1024
      - 5
      - 2
      - 64
    - - 512
      - 3
      - 1
      - 1
